{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sparse_ternary_networks.Tools as T\n",
    "import numpy as np\n",
    "import sparse_ternary_networks.MLSTC as MLSTC\n",
    "from scipy.linalg import eigh\n",
    "from scipy.linalg import toeplitz\n",
    "import matplotlib.pyplot as plt\n",
    "import RRQ.Tools as Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the parameters:\n",
    "n = 512      # dimension\n",
    "m = 512       # dimension of the codes\n",
    "N_train = 10000     # number of samples\n",
    "N_test = 10000     # number of samples\n",
    "k = 5         # number of non-zero elements of the STC at each stage.\n",
    "L = 70        # number of layer units of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRep = 1\n",
    "RhoList = [0.90]\n",
    "#RhoList = [0,0.5,0.99]\n",
    "MethodList = ['MLSTC']\n",
    "#MethodList = ['RQ']\n",
    "for RhoInd,Rho in enumerate(RhoList):\n",
    "    for Method in MethodList:\n",
    "        exec('dist_' + Method + '_Rho' + str(int(Rho*100)) + '_train = np.zeros((numRep,L+1))')\n",
    "        exec('dist_' + Method + '_Rho' + str(int(Rho*100)) + '_test = np.zeros((numRep,L+1))')\n",
    "        #\n",
    "        exec('rate_' + Method + '_Rho' + str(int(Rho*100)) + ' = np.zeros((numRep,L+1))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................  Repetition =  1\n",
      "....................  Rho =  0.9\n",
      " ############   MLSTC     A L G O R I T H M   ################\n",
      " ################## Starting to learn network parameters:  ##################\n",
      "layer-units:\n",
      "** 1 **** 2 **** 3 **** 4 **** 5 **** 6 **** 7 **** 8 **** 9 **** 10 **** 11 **** 12 **** 13 **** 14 **** 15 **\n",
      "** 16 **** 17 **** 18 **** 19 **** 20 **** 21 **** 22 **** 23 **** 24 **** 25 **** 26 **** 27 **** 28 **** 29 **** 30 **\n",
      "** 31 **** 32 **** 33 **** 34 **** 35 **** 36 **** 37 **** 38 **** 39 **** 40 **** 41 **** 42 **** 43 **** 44 **** 45 **\n",
      "** 46 **** 47 **** 48 **** 49 **** 50 **** 51 **** 52 **** 53 **** 54 **** 55 **** 56 **** 57 **** 58 **** 59 **** 60 **\n",
      "** 61 **** 62 **** 63 **** 64 **** 65 **** 66 **** 67 **** 68 **** 69 **** 70 **\n",
      "Finished learning network parameters:\n",
      " Running the network:\n",
      " ##################  Running the network:  ##################\n",
      "layer-units:\n",
      "** 1 **** 2 **** 3 **** 4 **** 5 **** 6 **** 7 **** 8 **** 9 **** 10 **** 11 **** 12 **** 13 **** 14 **** 15 **\n",
      "** 16 **** 17 **** 18 **** 19 **** 20 **** 21 **** 22 **** 23 **** 24 **** 25 **** 26 **** 27 **** 28 **** 29 **** 30 **\n",
      "** 31 **** 32 **** 33 **** 34 **** 35 **** 36 **** 37 **** 38 **** 39 **** 40 **** 41 **** 42 **** 43 **** 44 **** 45 **\n",
      "** 46 **** 47 **** 48 **** 49 **** 50 **** 51 **** 52 **** 53 **** 54 **** 55 **** 56 **** 57 **** 58 **** 59 **** 60 **\n",
      "** 61 **** 62 **** 63 **** 64 **** 65 **** 66 **** 67 **** 68 **** 69 **** 70 **\n",
      "Finished running the network.\n"
     ]
    }
   ],
   "source": [
    "for RepInd in range(numRep):\n",
    "    print('.......................................  Repetition = ',RepInd + 1)\n",
    "    for RhoInd,Rho in enumerate(RhoList):\n",
    "        print('....................  Rho = ',Rho)\n",
    "        F_train,F_test = Tools.data_generator(n,N_train,N_test,'AR1',SourceParam=Rho)\n",
    "        norm_train = np.divide(np.linalg.norm(F_train) ** 2, np.prod(F_train.shape))\n",
    "        norm_test = np.divide(np.linalg.norm(F_test) ** 2, np.prod(F_test.shape))\n",
    "        for MethodInd,Method in enumerate(MethodList):\n",
    "            print(' ############   ' + Method + '     A L G O R I T H M   ################')\n",
    "            \n",
    "                ###############################################\n",
    "            # training:\n",
    "            obj_train = MLSTC.BaseLearner(k,L,m=m)\n",
    "            _, _, _ = obj_train.run(F_train)\n",
    "            exec('dist_' + Method + '_Rho' + str(int(Rho*100)) + '_train[RepInd,:] = obj_train.distortion/norm_train')\n",
    "            exec('rate_' + Method + '_Rho' + str(int(Rho*100)) + '[RepInd,:] = obj_train.rate')\n",
    "            # testing:\n",
    "            obj_test = MLSTC.fwdPass(obj_train.params,k,ternaryProbMap=obj_train.prob_z)\n",
    "            _,_,_ = obj_test.run(F_test)\n",
    "            exec('dist_' + Method + '_Rho' + str(int(Rho*100)) + '_test[RepInd,:] = obj_test.distortion/norm_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_dict = {}\n",
    "for RhoInd,Rho in enumerate(RhoList):\n",
    "    for MethodInd,Method in enumerate(MethodList):\n",
    "        exec('x = np.mean(rate_' +  Method + '_Rho' + str(int(Rho*100)) + ',axis=0)')\n",
    "        exec('y = np.mean(dist_' +  Method + '_Rho' + str(int(Rho*100)) + '_train,axis=0)')\n",
    "        exec(\"curve_dict['Rho\" + str(int(Rho*100))+ '_n' + str(n)+ '_m' + str(m) +\"_DR_\"+ Method + \"_train'] = (x,y)\") \n",
    "        exec('y = np.mean(dist_' +  Method + '_Rho' + str(int(Rho*100)) + '_test,axis=0)')\n",
    "        exec(\"curve_dict['Rho\" + str(int(Rho*100))+ '_n' + str(n)+ '_m' + str(m) +\"_DR_\"+ Method + \"_test'] = (x,y)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyntheticAR1_STC_Rho90_n512_m512_DR_MLSTC_train.dat\n",
      "SyntheticAR1_STC_Rho90_n512_m512_DR_MLSTC_test.dat\n"
     ]
    }
   ],
   "source": [
    "# Saving the results for PGFplott:\n",
    "PGF_path = 'PGF/dat/'\n",
    "ExpName = 'SyntheticAR1_STC'\n",
    "#\n",
    "for curve_name, curve_xy in curve_dict.items():\n",
    "    fname = ExpName + '_' + curve_name + '.dat'\n",
    "    print(fname)\n",
    "    x = curve_xy[0].astype(float).reshape(-1)\n",
    "    y = curve_xy[1].astype(float).reshape(-1)\n",
    "    np.savetxt(PGF_path + fname, np.transpose([x,y]), fmt='%8f', delimiter='   ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
